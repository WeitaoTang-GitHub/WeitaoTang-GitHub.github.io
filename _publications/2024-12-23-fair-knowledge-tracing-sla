---
title: "Fair Knowledge Tracing in Second Language Acquisition"
collection: publications
category: manuscripts
permalink: /publication/fair-knowledge-tracing-sla
excerpt: "We study fairness in knowledge tracing for second language acquisition, proposing methods to improve predictive performance while mitigating biases across learner subgroups."
date: 2024-12-23
venue: "arXiv preprint"
paperurl: "https://arxiv.org/abs/2412.18048"
---
In second-language acquisition, predictive modeling aids educators in implementing diverse teaching strategies, attracting significant research attention. However, while model accuracy is widely explored, model fairness remains under-examined. Model fairness ensures equitable treatment of groups, preventing unintentional biases based on attributes such as gender, ethnicity, or economic background. A fair model should produce impartial outcomes that do not systematically disadvantage any group.
This study evaluates the fairness of two predictive models using the Duolingo dataset's en_es (English learners speaking Spanish), es_en (Spanish learners speaking English), and fr_en (French learners speaking English) tracks. We analyze: 1. Algorithmic fairness across platforms (iOS, Android, Web). 2. Algorithmic fairness between developed and developing countries.
Key findings include: 1. Deep learning outperforms machine learning in second-language knowledge tracing due to improved accuracy and fairness. 2. Both models favor mobile users over non-mobile users. 3. Machine learning exhibits stronger bias against developing countries compared to deep learning. 4. Deep learning strikes a better balance of fairness and accuracy in the en\_es and es\_en tracks, while machine learning is more suitable for fr\_en.
This study highlights the importance of addressing fairness in predictive models to ensure equitable educational strategies across platforms and regions.
